"""
SpiritAgent - The "Spirit" (DM - Thinking Module) of the entity.

Responsible for high-level thinking, analysis, and strategic planning.
Runs on a 3-second async loop.
"""

import asyncio
import json
from datetime import datetime
from typing import Any, Callable, Optional
from dataclasses import dataclass, field

from living_entity.agents.abstract import AbstractAgent, AgentConfig
from living_entity.memory.matrix import MemoryMatrix
from living_entity.memory.context_reducer import ContextReducer
from living_entity.prompts.spirit_prompts import (
    SPIRIT_SYSTEM_PROMPT,
    SPIRIT_ANALYSIS_PROMPT,
    SPIRIT_REFLECTION_PROMPT,
)
from living_entity.utils.logging import get_logger


@dataclass
class Signal:
    """An incoming signal to be processed."""
    content: str
    source: str = "unknown"
    timestamp: datetime = field(default_factory=datetime.now)
    priority: str = "medium"
    metadata: dict = field(default_factory=dict)


@dataclass
class SpiritCommand:
    """A command generated by the Spirit."""
    type: str  # "remember", "delegate", "focus"
    content: str
    priority: str = "medium"
    metadata: dict = field(default_factory=dict)


class SpiritAgent(AbstractAgent):
    """
    The Spirit Agent (DM - Thinking Module).
    
    Responsibilities:
    - High-level thinking and analysis
    - Reading and processing input signals
    - Memory retrieval and storage
    - Task delegation to Brain
    
    Runs on a 3-second async loop.
    """
    
    LOOP_INTERVAL = 3.0  # seconds
    
    def __init__(
        self,
        api_key: str,
        base_url: Optional[str] = None,
        model: str = "gpt-3.5-turbo",
        config: Optional[AgentConfig] = None,
        memory: Optional[MemoryMatrix] = None,
        client_kwargs: Optional[dict] = None,
    ):
        """
        Initialize the Spirit Agent.
        
        :param api_key: API key for LLM provider
        :param base_url: Base URL for API
        :param model: Model name
        :param config: Agent configuration
        :param memory: Shared memory matrix
        :param client_kwargs: Additional client kwargs
        """
        super().__init__(
            api_key=api_key,
            base_url=base_url,
            model=model,
            config=config,
            client_kwargs=client_kwargs,
        )
        
        # Set system prompt
        self.set_system_prompt(SPIRIT_SYSTEM_PROMPT)
        
        # Memory
        self.memory = memory
        
        # Context reducer (initialized later with client)
        self._context_reducer: Optional[ContextReducer] = None
        
        # Signal queue
        self._signal_queue: asyncio.Queue[Signal] = asyncio.Queue()
        
        # Command output queue (for Brain to consume)
        self._command_queue: asyncio.Queue[SpiritCommand] = asyncio.Queue()
        
        # Running state
        self._running = False
        self._loop_task: Optional[asyncio.Task] = None
        
        # Waiting state - pause processing until user responds
        self._waiting_for_user = False
        
        # Context accumulator
        self._current_context: list[str] = []
        self._max_context_items = 10
        
        # Callbacks
        self._on_thought: Optional[Callable[[str], None]] = None
        self._on_command: Optional[Callable[[SpiritCommand], None]] = None
    
    def set_context_reducer(self, reducer: ContextReducer) -> None:
        """Set the context reducer."""
        self._context_reducer = reducer
    
    def on_thought(self, callback: Callable[[str], None]) -> None:
        """Register callback for thoughts."""
        self._on_thought = callback
    
    def on_command(self, callback: Callable[[SpiritCommand], None]) -> None:
        """Register callback for commands."""
        self._on_command = callback
    
    async def receive_signal(self, signal: Signal) -> None:
        """
        Receive an incoming signal.
        
        :param signal: Signal to process
        """
        await self._signal_queue.put(signal)
        self.logger.debug(f"Signal queued: {signal.content[:50]}...", module="spirit")
    
    async def receive_input(
        self,
        content: str,
        source: str = "user",
        priority: str = "medium",
    ) -> None:
        """
        Convenience method to receive text input.
        
        :param content: Input text
        :param source: Source identifier
        :param priority: Priority level
        """
        # Reset waiting state when user sends a message
        if source == "user":
            self._waiting_for_user = False
            self.logger.debug("Waiting state reset - user input received", module="spirit")
        
        signal = Signal(content=content, source=source, priority=priority)
        await self.receive_signal(signal)
    
    def get_command_queue(self) -> asyncio.Queue[SpiritCommand]:
        """Get the command queue for Brain to consume."""
        return self._command_queue
    
    async def process(self) -> None:
        """
        Main processing cycle.
        
        1. Read signals from queue
        2. Retrieve memory context
        3. Analyze and generate response
        4. Process commands
        """
        # If waiting for user, skip processing to save tokens
        if self._waiting_for_user and self._signal_queue.empty():
            return
        
        # Collect signals (batch processing)
        signals: list[Signal] = []
        
        while not self._signal_queue.empty():
            try:
                signal = self._signal_queue.get_nowait()
                signals.append(signal)
            except asyncio.QueueEmpty:
                break
        
        if not signals:
            # No signals and not waiting - do idle thinking
            if not self._waiting_for_user:
                await self._idle_reflection()
            return
        
        # Process each signal
        for signal in signals:
            await self._process_signal(signal)
    
    async def _process_signal(self, signal: Signal) -> None:
        """Process a single signal."""
        self.logger.thought(f"Processing signal from {signal.source}")
        
        # Handle brain_action signals differently - these are reports from MM
        # DM should only observe them, not respond as if user is speaking
        if signal.source == "brain_action":
            # Just add to context for awareness, no need to generate response
            self._current_context.append(f"[ММ отчёт] {signal.content[:200]}")
            self.logger.debug("Brain action observed, not responding", module="spirit")
            return
        
        # Get memory context - ALWAYS include foundational memories
        memories_text = ""
        if self.memory:
            # First, get foundational (personality) memories
            foundational_memories = self.memory.retrieve(
                "personality",
                threshold=0.0,  # Get all foundational memories
                max_results=10,
            )
            # Filter to only foundational ones
            foundational_texts = [
                f"- {m.entry.text}" 
                for m in foundational_memories 
                if m.entry.source == "personality" or m.entry.metadata.get("type") == "foundational"
            ]
            
            # Then get relevant memories for the signal
            relevant_memories = self.memory.auto_associative_search(
                signal.content,
                max_results=3,
            )
            relevant_texts = [
                f"- [{m.entry.source}] {m.entry.text}"
                for m in relevant_memories
                if m.entry.source != "personality"  # Don't duplicate
            ]
            
            # Combine: foundational first, then relevant
            all_memories = []
            if foundational_texts:
                all_memories.append("Моя личность:")
                all_memories.extend(foundational_texts)
            if relevant_texts:
                if foundational_texts:
                    all_memories.append("\nРелевантные воспоминания:")
                all_memories.extend(relevant_texts)
            
            memories_text = "\n".join(all_memories)
        
        # Log retrieved memories
        if memories_text:
            self.logger.info(f"[ДМ] Найденные воспоминания:\n{memories_text}", module="spirit")
        
        # Build context
        context = "\n".join(self._current_context[-self._max_context_items:])
        
        # Format prompt with timestamps
        from datetime import datetime
        current_time = datetime.now().strftime("%H:%M:%S")
        signal_time = signal.timestamp.strftime("%H:%M:%S") if hasattr(signal, 'timestamp') else current_time
        
        prompt = SPIRIT_ANALYSIS_PROMPT.format(
            current_time=current_time,
            context=context if context else "Нет предыдущего контекста",
            memories=memories_text if memories_text else "Нет релевантных воспоминаний",
            source=signal.source,
            signal_time=signal_time,
            signal=signal.content,
        )
        
        # Reduce context if needed
        if self._context_reducer:
            history = self.get_history()
            if self._context_reducer.needs_reduction(history):
                reduced = await self._context_reducer.reduce(history)
                self.set_history(reduced)
        
        # Get response from LLM
        try:
            response = await self.think(prompt, include_history=True, json_mode=True)
        except Exception as e:
            self.logger.error(f"Spirit thinking failed: {e}", module="spirit")
            return
        
        # Parse response
        parsed = self.parse_json_response(response)
        if not parsed:
            self.logger.warning("Failed to parse Spirit response", module="spirit")
            return
        
        # Log thought
        thought = parsed.get("thought", "")
        if thought:
            self.logger.thought(thought)
            if self._on_thought:
                self._on_thought(thought)
        
        # Update context
        self._current_context.append(f"[{signal.source}] {signal.content}")
        if thought:
            self._current_context.append(f"[spirit] {thought}")
        
        # Process commands - pass thought so Brain sees DM's reasoning
        commands = parsed.get("commands", [])
        await self._process_commands(commands, thought=thought)
    
    async def _process_commands(self, commands: list[dict], thought: str = "") -> None:
        """
        Process commands from Spirit response.
        
        :param commands: List of command dictionaries
        :param thought: Spirit's thought to include in Brain commands (MM sees DM's thoughts)
        """
        for cmd_data in commands:
            cmd_type = cmd_data.get("type", "")
            content = cmd_data.get("content", "")
            priority = cmd_data.get("priority", "medium")
            
            if not cmd_type or not content:
                continue
            
            # For commands going to Brain, prepend Spirit's thought
            # so MM can see DM's reasoning
            enriched_content = content
            if cmd_type in ("do", "delegate", "focus") and thought:
                enriched_content = f"[Мысли ДМ: {thought}]\n\n{content}"
            
            command = SpiritCommand(
                type=cmd_type,
                content=enriched_content if cmd_type in ("do", "delegate", "focus") else content,
                priority=priority,
            )
            
            if cmd_type == "remember":
                # Filter out memories about user messages - we only want self-reflections
                content_lower = content.lower()
                user_related_phrases = [
                    "пользователь", "собеседник", "он спросил", "она спросила",
                    "спросил мое", "спросила мое", "спросил что", "спросила что",
                    "поздоровался", "поздоровалась", "написал", "написала",
                    "user asked", "user said", "user wants"
                ]
                
                if any(phrase in content_lower for phrase in user_related_phrases):
                    self.logger.debug(f"Skipped user-related memory: {content[:30]}...", module="spirit")
                    continue
                
                # Save to memory - only self-reflections
                if self.memory:
                    self.memory.save_memory(
                        text=content,
                        source="spirit",
                        importance=0.7 if priority == "high" else 0.5,
                    )
                self.logger.memory(f"Remembered: {content[:50]}...")
            
            elif cmd_type == "wait":
                # Wait for user - set waiting state
                self._waiting_for_user = True
                self.logger.info("Waiting for user response...", module="spirit")
                
            elif cmd_type in ("do", "delegate", "focus"):
                # Send to command queue for Brain
                # Treat "do" as "delegate" for backwards compatibility
                if cmd_type == "do":
                    command.type = "delegate"
                await self._command_queue.put(command)
                self.logger.info(
                    f"Command queued: {command.type} - {content[:50]}...",
                    module="spirit"
                )
                
                # Call callback
                if self._on_command:
                    self._on_command(command)
    
    async def _idle_reflection(self) -> None:
        """Perform idle reflection when no signals."""
        # Only reflect occasionally (every ~5 cycles on average)
        import random
        if random.random() > 0.2:
            return
        
        self.logger.debug("Idle reflection...", module="spirit")
        
        # Check if there's anything to reflect on
        if not self._current_context:
            return
        
        # Build reflection prompt
        recent_context = "\n".join(self._current_context[-5:])
        
        prompt = SPIRIT_REFLECTION_PROMPT.format(
            recent_actions=recent_context,
            results="Ожидание результатов...",
        )
        
        try:
            response = await self.think(prompt, include_history=False, json_mode=True)
            parsed = self.parse_json_response(response)
            
            if parsed:
                thought = parsed.get("thought", "")
                if thought:
                    self.logger.thought(f"[reflection] {thought}")
                
                commands = parsed.get("commands", [])
                if commands:
                    await self._process_commands(commands)
                    
        except Exception as e:
            self.logger.debug(f"Idle reflection failed: {e}", module="spirit")
    
    async def run_loop(self, interval: Optional[float] = None) -> None:
        """
        Run the Spirit's main loop.
        
        :param interval: Loop interval in seconds (default: 3.0)
        """
        self._running = True
        loop_interval = interval or self.LOOP_INTERVAL
        
        self.logger.info(
            f"Spirit loop started (interval: {loop_interval}s)",
            module="spirit"
        )
        
        while self._running:
            try:
                await self.process()
            except Exception as e:
                self.logger.error(f"Spirit loop error: {e}", module="spirit")
            
            await asyncio.sleep(loop_interval)
        
        self.logger.info("Spirit loop stopped", module="spirit")
    
    def start(self) -> asyncio.Task:
        """Start the Spirit loop as a background task."""
        if self._loop_task and not self._loop_task.done():
            return self._loop_task
        
        self._loop_task = asyncio.create_task(self.run_loop())
        return self._loop_task
    
    def stop(self) -> None:
        """Stop the Spirit loop."""
        self._running = False
        if self._loop_task:
            self._loop_task.cancel()
    
    def is_running(self) -> bool:
        """Check if the Spirit is running."""
        return self._running
    
    def get_context(self) -> list[str]:
        """Get the current context."""
        return self._current_context.copy()
    
    def clear_context(self) -> None:
        """Clear the current context."""
        self._current_context.clear()
